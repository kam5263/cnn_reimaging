import tensorflow as tf
import numpy as np
import pandas as pd
import os
import gc
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm

# í•œê¸€ í°íŠ¸ ì„¤ì • (macOS)
plt.rcParams['font.family'] = 'AppleGothic'
plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

# --- 1. ìƒìˆ˜ ì •ì˜ ---
NPZ_FILE = 'data_L5_R5_with_returns.npz' # ìˆ˜ìµë¥ ì´ í¬í•¨ëœ ìƒˆ NPZ íŒŒì¼
MODEL_FILE = 'cnn_L5_R5_model.keras'      # í›ˆë ¨ëœ ëª¨ë¸ íŒŒì¼
IMAGE_SHAPE = (32, 15, 1)
NUM_CLASSES = 2

# --- 2. ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (ìˆ˜ìµë¥  í¬í•¨) ---
def load_data_for_backtest(npz_path):
    print(f"'{npz_path}' íŒŒì¼ì—ì„œ ë°±í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì¤‘...")
    if not os.path.exists(npz_path):
        print(f"ì˜¤ë¥˜: '{npz_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, None, None
        
    with np.load(npz_path, allow_pickle=True) as data:
        images = data['images']
        dates = data['dates']
        returns = data['returns'] # 'labels' ëŒ€ì‹  'returns'ë¥¼ ë¡œë“œ

    print("ë°ì´í„° ë¡œë“œ ì™„ë£Œ.")
    print(f"  ì´ë¯¸ì§€ (X) í˜•íƒœ: {images.shape}")
    print(f"  ë‚ ì§œ (dates) í˜•íƒœ: {dates.shape}")
    print(f"  ìˆ˜ìµë¥  (returns) í˜•íƒœ: {returns.shape}")
    
    images = images.astype('uint8')
    returns = returns.astype('float32')
    
    return images, dates, returns

# --- 3. ë©”ì¸ ì‹¤í–‰ ---
if __name__ == "__main__":
    
    # 1. ë°±í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
    X_data, dates_data, returns_data = load_data_for_backtest(NPZ_FILE)
    if X_data is None:
        exit()

    # 2. í›ˆë ¨/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„í•  (train_model.pyì™€ ë™ì¼í•œ ë¡œì§)
    print("\n--- í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ë¶„í•  (ì‹œê³„ì—´ ê¸°ì¤€) ---")
    try:
        dates_np = dates_data.astype('datetime64[D]')
    except ValueError:
        print("ì˜¤ë¥˜: 'dates' ë°°ì—´ì„ ë‚ ì§œë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        exit()

    split_date = np.datetime64('2001-01-01')
    test_mask = (dates_np >= split_date)

    # í…ŒìŠ¤íŠ¸ì— í•„ìš”í•œ ë°ì´í„°ë§Œ ì¶”ì¶œ
    X_test = X_data[test_mask]
    dates_test = dates_data[test_mask]
    returns_test = returns_data[test_mask] # â­ï¸ ì‹¤ì œ ìˆ˜ìµë¥  í…ŒìŠ¤íŠ¸ì…‹

    print(f"í…ŒìŠ¤íŠ¸ (2001-) ë°ì´í„°: {X_test.shape[0]}ê°œ ìƒ˜í”Œ")

    # ë©”ëª¨ë¦¬ ì ˆì•½
    del X_data, dates_data, returns_data, test_mask
    gc.collect()

    # 3. í›ˆë ¨ëœ ëª¨ë¸ ë¡œë“œ
    print(f"\n--- í›ˆë ¨ëœ ëª¨ë¸ ({MODEL_FILE}) ë¡œë“œ ì¤‘ ---")
    if not os.path.exists(MODEL_FILE):
        print(f"ì˜¤ë¥˜: '{MODEL_FILE}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € í›ˆë ¨ì‹œì¼œ ì£¼ì„¸ìš”.")
        exit()
    model = tf.keras.models.load_model(MODEL_FILE)
    print("ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

    # 4. í…ŒìŠ¤íŠ¸ì…‹ì— ëŒ€í•œ 'Up' í™•ë¥  ì˜ˆì¸¡
    # ğŸš¨ ì´ ì‘ì—…ì€ 1700ë§Œ ê°œ+ ë°ì´í„°ì— ëŒ€í•´ ì‹¤í–‰ë˜ë¯€ë¡œ ì‹œê°„ì´ ê±¸ë¦½ë‹ˆë‹¤!
    print(f"\n--- í…ŒìŠ¤íŠ¸ì…‹ ({X_test.shape[0]}ê°œ) ì˜ˆì¸¡ ì‹œì‘ ---")
    # model.predict()ëŠ” [P(Down), P(Up)]ì„ ë°˜í™˜
    # ìš°ë¦¬ëŠ” 'Up' í™•ë¥ ì¸ ë‘ ë²ˆì§¸ ê°’ [:, 1]ì´ í•„ìš”
    predictions = model.predict(X_test, batch_size=1024, verbose=1)
    up_probabilities = predictions[:, 1]
    print("ì˜ˆì¸¡ ì™„ë£Œ.")

    # 5. ë°±í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°í”„ë ˆì„ ìƒì„±
    print("\n--- ë°±í…ŒìŠ¤íŠ¸ìš© ë°ì´í„°í”„ë ˆì„ ìƒì„± ---")
    df = pd.DataFrame({
        'date': pd.to_datetime(dates_test), # ë‚ ì§œë¥¼ datetime ê°ì²´ë¡œ
        'signal_prob': up_probabilities,   # ëª¨ë¸ì´ ì˜ˆì¸¡í•œ 'Up' í™•ë¥ 
        'actual_return': returns_test      # í•´ë‹¹ ì£¼ì‹ì˜ 5ì¼ ë’¤ ì‹¤ì œ ìˆ˜ìµë¥ 
    })
    
    # ë‚ ì§œë³„ë¡œ ê·¸ë£¹í™”í•  ìˆ˜ ìˆë„ë¡ ë‚ ì§œë¥¼ ì¸ë±ìŠ¤ë¡œ ì„¤ì •
    df = df.set_index('date').sort_index()
    print(df.head())

# 6. ë¡±ìˆ(Long-Short) í¬íŠ¸í´ë¦¬ì˜¤ ë°±í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    print("\n--- ë¡±ìˆ í¬íŠ¸í´ë¦¬ì˜¤ ë°±í…ŒìŠ¤íŠ¸ (ì£¼ê°„ ë¦¬ë°¸ëŸ°ì‹± + ê·¹ë‹¨ê°’ ì œê±°) ---")
    
    daily_groups = df.groupby(df.index)
    strategy_returns = [] 
    
    from tqdm import tqdm
    for date, group in tqdm(daily_groups, desc="ë°±í…ŒìŠ¤íŠ¸ ì§„í–‰ ì¤‘"):
        
        # 1. ì£¼ê°„ ë¦¬ë°¸ëŸ°ì‹± (ì›”ìš”ì¼ì—ë§Œ ì‹¤í–‰)
        if date.weekday() != 0:
            continue
            
        if len(group) < 10:
            continue
            
        # â­ï¸ [ì‹ ê·œ ìˆ˜ì •] â­ï¸
        # Winsorization (ê·¹ë‹¨ê°’ ì œê±°)
        # 5ì¼ ìˆ˜ìµë¥ ì˜ ê·¹ë‹¨ì ì¸ ì˜¤ë¥˜ê°’ì„ ì œê±°í•©ë‹ˆë‹¤.
        # ë§¤ì¼ ìƒìœ„ 1%(q_99)ì™€ í•˜ìœ„ 1%(q_01)ë¥¼ ì´ˆê³¼í•˜ëŠ” ê°’ì€
        # ê°ê° 99%ì™€ 1%ì˜ ê°’ìœ¼ë¡œ 'ìº¡(cap)'ì„ ì”Œì›ë‹ˆë‹¤.
        q_01 = group['actual_return'].quantile(0.01)
        q_99 = group['actual_return'].quantile(0.99)
        
        # q_01ë³´ë‹¤ ì‘ìœ¼ë©´ q_01ë¡œ, q_99ë³´ë‹¤ í¬ë©´ q_99ë¡œ ê°’ì„ ì œí•œ
        group['actual_return_clipped'] = group['actual_return'].clip(lower=q_01, upper=q_99)
        
        # 2. 10ë¶„ìœ„ ê³„ì‚° (ì‹œê·¸ë„ ê¸°ì¤€)
        try:
            # ì‹œê·¸ë„(prob)ì„ ê¸°ì¤€ìœ¼ë¡œ ì£¼ì‹ì„ ì¤„ ì„¸ì›ë‹ˆë‹¤.
            group['decile'] = pd.qcut(group['signal_prob'], 10, labels=False, duplicates='drop')
        except ValueError:
            continue 

        # 3. í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ê³„ì‚° (í´ë¦° ë°ì´í„° ê¸°ì¤€)
        # â­ï¸ [ì‹ ê·œ ìˆ˜ì •] â­ï¸
        # 'actual_return' ëŒ€ì‹  ê¹¨ë—í•´ì§„ 'actual_return_clipped'ì˜ í‰ê· ì„ ì‚¬ìš©
        long_return = group[group['decile'] == 9]['actual_return_clipped'].mean()
        short_return = group[group['decile'] == 0]['actual_return_clipped'].mean()
        
        if pd.isna(long_return) or pd.isna(short_return):
            continue

        weekly_strategy_return = long_return - short_return
        strategy_returns.append(pd.Series([weekly_strategy_return], index=[date]))

    # 7. ìµœì¢… ì„±ê³¼ ë¶„ì„ (ì´ ë¶€ë¶„ì€ ë™ì¼í•©ë‹ˆë‹¤)
    print("\n--- ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ---")
    
    if not strategy_returns:
        print("ì˜¤ë¥˜: ë°±í…ŒìŠ¤íŠ¸ ìˆ˜ìµë¥ ì´ ê³„ì‚°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        exit()

    weekly_returns = pd.concat(strategy_returns)
    clipped_weekly_returns = weekly_returns.clip(lower=-0.99)
    cumulative_returns = (1 + clipped_weekly_returns).cumprod()

    mean_weekly_return = weekly_returns.mean()
    std_weekly_return = weekly_returns.std()
    
    annualized_sharpe_ratio = 0.0
    if std_weekly_return > 0:
        annualized_sharpe_ratio = (mean_weekly_return / std_weekly_return) * np.sqrt(52)

    print(f"í…ŒìŠ¤íŠ¸ ê¸°ê°„: 2001-01-01 ~ 2019-12-31 (ë°ì´í„° ê¸°ì¤€)")
    print(f"ì´ ì£¼ê°„ ìˆ˜ìµë¥  í‰ê· : {mean_weekly_return*100:.4f} %")
    print(f"ì´ ì£¼ê°„ ìˆ˜ìµë¥  ë³€ë™ì„±: {std_weekly_return*100:.4f} %")
    print(f"ì—°ê°„ ìƒ¤í”„ ë¹„ìœ¨ (Annualized Sharpe Ratio): {annualized_sharpe_ratio:.4f}")
    
    # 8. ëˆ„ì  ìˆ˜ìµë¥  ê·¸ë˜í”„ ì‹œê°í™” (ì´ ë¶€ë¶„ì€ ë™ì¼í•©ë‹ˆë‹¤)
    plt.figure(figsize=(10, 6))
    cumulative_returns.plot()
    plt.title('CNN ë¡±ìˆ í¬íŠ¸í´ë¦¬ì˜¤ ëˆ„ì  ìˆ˜ìµë¥  (ì£¼ê°„, ê·¹ë‹¨ê°’ ì œê±°, 2001~)')
    plt.xlabel('ë‚ ì§œ')
    plt.ylabel('ëˆ„ì  ìˆ˜ìµ (1$ ê¸°ì¤€)')
    plt.grid(True)
    plt.yscale('log')
    plt.savefig('cumulative_returns_L5_R5.png')
    print("ëˆ„ì  ìˆ˜ìµë¥  ê·¸ë˜í”„ê°€ 'cumulative_returns_L5_R5.png'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")